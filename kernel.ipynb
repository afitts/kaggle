{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from fastai.conv_learner import *\nfrom fastai.dataset import *\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nimport scipy.optimize as opt\n\nprint(os.listdir(\"../input/\"))\n",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['train', 'test', 'train.csv', 'sample_submission.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "**Sections of this kernel**\n1. Project understanding\n- Data understanding\n- Data visualization\n- Baseline model\n- Validation and analysis\n    - Metrics\n    - Prediction visualizations\n    - Confusion matrix\n    - macro F1 score\n- Submit\n\n---------------------------------------------------\n\n# Project understanding\n###  What exactly is the problem?\n\n**Multi-class, multi-label image classification problem.** We are predicting protein organelle localization labels for each sample. There are in total 28 different labels present in the dataset.  All image samples are represented by four filters (stored as individual files), the protein of interest (green) plus three cellular landmarks: nucleus (blue), microtubules (red), endoplasmic reticulum (yellow). The green filter should hence be used to predict the label, and the other filters are used as references. \n\nA number of key challenges exist for the dataset.\n1. The images are quite different from what ImageNet has been trained on. Not only are the images themselves different in content, but they also have 4 channels (RGBY) as opposed to the usual 3 (RGB). Hence, while using a pretrained network will provide a benefit when first training, substaintial retraining will be necesary.\n\n**Our evaluation metric is the [macro F1 score](https://en.wikipedia.org/wiki/F1_score).** The F1 score is a (harmonic) average of the precision and recall of our model, where precision is the true positives divided by all positives identified by the model (true positives + false positives) and the recall is the true positives divided by all the actual positives (true positives + false negatives).\n"
    },
    {
      "metadata": {
        "_uuid": "f8800cd82f77bdf42199b2e21cce91e8e1944d17"
      },
      "cell_type": "markdown",
      "source": "----------------------------------------------\n# Data understanding\n### What data do we have available?\n\n**31.1k training images and 11.7k evaluation images.** The dataset is a subset of the [PCam dataset](https://github.com/basveeling/pcam) and the only difference between these two is that all duplicate images have been removed. The PCam dataset is derived from the [Camelyon16 Challenge dataset](https://camelyon16.grand-challenge.org/Data/) which contains 400 H&E stained whole slide images of sentinel lymph node sections that were acquired and digitized at 2 different centers using a 40x objective. The PCam's dataset including this one uses 10x undersampling to increase the field of view, which gives the resultant pixel resolution of 2.43 microns.\n\nAccording to the data description, there is a 50/50 balance between positive and negative examples in the training and test splits. However, **the training distribution seems to be 60/40 (negatives/positives)**. A positive label means that there is at least one pixel of tumor tissue in the center region (32 x 32px) of the image. **Tumor tissue in the outer region of the patch does not influence the label.** This means that a negatively labeled image could contain metastases in the outer region. Thus, it would be a good idea to crop the images to the center region.\n\n**Image file descriptors**\n\nDescription | \n:--------:|:-------:\nFormat | PNG\nSize | 512 x 512\nChannels | 4\nBits per channel | 8\nData type | Unsigned char\nCompression | PNG\n\n**External Data** There is a large cache of data that has been \"leaked\", see [this discussion post](https://www.kaggle.com/c/human-protein-atlas-image-classification/discussion/69984#432870).  [126 test matches found by Brian ](https://storage.googleapis.com/kaggle-forum-message-attachments/433234/10820/overlap.py) [Test matches found by Tomomi Moriyama with labels from HPA](https://storage.googleapis.com/kaggle-forum-message-attachments/432969/10817/test_matches.csv)\n\n\n### Is the data relevant to the problem?\n\nThis dataset is a combination of two independent datasets collected in Radboud University Medical Center (Nijmegen, the Netherlands), and the University Medical Center Utrecht (Utrecht, the Netherlands). The slides are produced by routine clinical practices and a trained pathologist would examine similar images for identifying metastases. However, some relevant information about the surroundings might be left out with these small-sized image samples.\n\n### Is it valid? Does it reflect our expectations?\n\nAccording to the data description, the dataset has been stripped of duplicates. However, this has not been confirmed by testing.\n\n> For the entire dataset, when the slide-level label was unclear during the inspection of the H&E-stained slide, an additional WSI with a consecutive tissue section, immunohistochemically stained for cytokeratin, was used to confirm the classification.\n- [1399 H&E-stained sentinel lymph node sections of breast cancer patients: the CAMELYON dataset](https://academic.oup.com/gigascience/article/7/6/giy065/5026175)\n\n### Is the data quality, quantity, recency sufficient?\n\n> All glass slides included in the CAMELYON dataset were part of routine clinical care and are thus of diagnostic quality. However, during the acquisition process, scanning can fail or result in out-of-focus images. As a quality-control measure, all slides were inspected manually after scanning. The inspection was performed by an experienced technician (Q.M. and N.S. for UMCU, M.H. or R.vd.L. for the other centers) to assess the quality of the scan; when in doubt, a pathologist was consulted on whether scanning issues might affect diagnosis.\n- [1399 H&E-stained sentinel lymph node sections of breast cancer patients: the CAMELYON dataset](https://academic.oup.com/gigascience/article/7/6/giy065/5026175)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2405533263ddb195f44a5ab3f3c81dab1e5de88c"
      },
      "cell_type": "code",
      "source": "PATH = './'\nTRAIN = '../input/train/'\nTEST = '../input/test/'\nLABELS = '../input/train.csv'\nSAMPLE = '../input/sample_submission.csv'\n\ndata = pd.read_csv(f'{LABELS}')\n\n# quick look at the label stats\ndata.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "717ede1db4ca6a622f7589e20193ee52249f38f7"
      },
      "cell_type": "code",
      "source": "name_label_dict = {\n0:  \"Nucleoplasm\", \n1:  \"Nuclear membrane\",   \n2:  \"Nucleoli\",   \n3:  \"Nucleoli fibrillar center\" ,  \n4:  \"Nuclear speckles\",\n5:  \"Nuclear bodies\",\n6:  \"Endoplasmic reticulum\",   \n7:  \"Golgi apparatus\",\n8:  \"Peroxisomes\",\n9:  \"Endosomes\",\n10:  \"Lysosomes\",\n11:  \"Intermediate filaments\",   \n12:  \"Actin filaments\",\n13:  \"Focal adhesion sites\",   \n14:  \"Microtubules\",\n15:  \"Microtubule ends\",   \n16:  \"Cytokinetic bridge\",   \n17:  \"Mitotic spindle\",\n18:  \"Microtubule organizing center\",  \n19:  \"Centrosome\",\n20:  \"Lipid droplets\",   \n21:  \"Plasma membrane\",   \n22:  \"Cell junctions\", \n23:  \"Mitochondria\",\n24:  \"Aggresome\",\n25:  \"Cytosol\",\n26:  \"Cytoplasmic bodies\",   \n27:  \"Rods & rings\" \n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f22943eda40d5661743514edfb37b0096da6e1a2"
      },
      "cell_type": "code",
      "source": "nw = 2   #number of workers for data loader\narch = resnet34 #specify target architecture",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "29919ab483dbf016e366cd67380377c9509fdab5"
      },
      "cell_type": "code",
      "source": "train_names = list({f[:36] for f in os.listdir(TRAIN)})\ntest_names = list({f[:36] for f in os.listdir(TEST)})\ntr_n, val_n = train_test_split(train_names, test_size=0.1, random_state=42)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "78477c3da1f58bd0648983c0c1dddc9edf3dcae3"
      },
      "cell_type": "code",
      "source": "def open_rgby(path,id): #a function that reads RGBY image\n    colors = ['red','green','blue','yellow']\n    flags = cv2.IMREAD_GRAYSCALE\n    img = [cv2.imread(os.path.join(path, id+'_'+color+'.png'), flags).astype(np.float32)/255\n           for color in colors]\n    return np.stack(img, axis=-1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d5255041e0cf6e09d1c83dccb04147c74ed695ea"
      },
      "cell_type": "code",
      "source": "class pdFilesDataset(FilesDataset):\n    def __init__(self, fnames, path, transform):\n        self.labels = pd.read_csv(LABELS).set_index('Id')\n        self.labels['Target'] = [[int(i) for i in s.split()] for s in self.labels['Target']]\n        super().__init__(fnames, transform, path)\n    \n    def get_x(self, i):\n        img = open_rgby(self.path,self.fnames[i])\n        if self.sz == 512: return img \n        else: return cv2.resize(img, (self.sz, self.sz),cv2.INTER_AREA) #resize images\n    \n    def get_y(self, i):\n        if(self.path == TEST): return np.zeros(len(name_label_dict),dtype=np.int)\n        else:\n            labels = self.labels.loc[self.fnames[i]]['Target']\n            return np.eye(len(name_label_dict),dtype=np.float)[labels].sum(axis=0)\n        \n    @property\n    def is_multi(self): return True\n    @property\n    def is_reg(self):return True\n    #this flag is set to remove the output sigmoid that allows log(sigmoid) optimization\n    #of the numerical stability of the loss function\n    \n    def get_c(self): return len(name_label_dict) #number of classes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "05df66ef4fa10a367b64f1f07341b97b6a799f05"
      },
      "cell_type": "code",
      "source": "def get_data(sz,bs):\n    #data augmentation\n    aug_tfms = [RandomRotate(30, tfm_y=TfmType.NO),\n                RandomDihedral(tfm_y=TfmType.NO),\n                RandomLighting(0.05, 0.05, tfm_y=TfmType.NO)]\n    #mean and std in of each channel in the train set\n    stats = A([0.08069, 0.05258, 0.05487, 0.08282], [0.13704, 0.10145, 0.15313, 0.13814])\n    tfms = tfms_from_stats(stats, sz, crop_type=CropType.NO, tfm_y=TfmType.NO, \n                aug_tfms=aug_tfms)\n    ds = ImageData.get_ds(pdFilesDataset, (tr_n[:-(len(tr_n)%bs)],TRAIN), \n                (val_n,TRAIN), tfms, test=(test_names,TEST))\n    md = ImageData(PATH, ds, bs, num_workers=nw, classes=None)\n    return md",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de3709858e791257e45dd4cdc5c78e2030104398"
      },
      "cell_type": "code",
      "source": "bs = 16\nsz = 256\nmd = get_data(sz,bs)\n\nx,y = next(iter(md.trn_dl))\nx.shape, y.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ba0e386b95517f2d998cceb9c5eedee951eff8d8"
      },
      "cell_type": "code",
      "source": "def display_imgs(x):\n    columns = 4\n    bs = x.shape[0]\n    rows = min((bs+3)//4,4)\n    fig=plt.figure(figsize=(columns*4, rows*4))\n    for i in range(rows):\n        for j in range(columns):\n            idx = i+j*columns\n            fig.add_subplot(rows, columns, idx+1)\n            plt.axis('off')\n            plt.imshow((x[idx,:,:,:3]*255).astype(np.int))\n    plt.show()\n    \ndisplay_imgs(np.asarray(md.trn_ds.denorm(x)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6533760fd30c62382da7d421a351b921fc7a9f91"
      },
      "cell_type": "code",
      "source": "x_tot = np.zeros(4)\nx2_tot = np.zeros(4)\nfor x,y in iter(md.trn_dl):\n    tmp =  md.trn_ds.denorm(x).reshape(16,-1)\n    x = md.trn_ds.denorm(x).reshape(-1,4)\n    x_tot += x.mean(axis=0)\n    x2_tot += (x**2).mean(axis=0)\n\nchannel_avr = x_tot/len(md.trn_dl)\nchannel_std = np.sqrt(x2_tot/len(md.trn_dl) - channel_avr**2)\nchannel_avr,channel_std",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fc521af51f9e2358d6efe5e3a34cb1917f200cad"
      },
      "cell_type": "markdown",
      "source": "(array([0.08687, 0.05979, 0.06532, 0.089  ]),\n array([0.13042, 0.09819, 0.14864, 0.13292]))\n "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "59d76bfa7c92f5b095843bb98487d95403ab16e5"
      },
      "cell_type": "code",
      "source": "class FocalLoss(nn.Module):\n    def __init__(self, gamma=2):\n        super().__init__()\n        self.gamma = gamma\n        \n    def forward(self, input, target):\n        if not (target.size() == input.size()):\n            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n                             .format(target.size(), input.size()))\n\n        max_val = (-input).clamp(min=0)\n        loss = input - input * target + max_val + \\\n            ((-max_val).exp() + (-input - max_val).exp()).log()\n\n        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n        loss = (invprobs * self.gamma).exp() * loss\n        \n        return loss.sum(dim=1).mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "cc081b3d6900739052b23ffada3e76a216824f3f"
      },
      "cell_type": "code",
      "source": "class ConvnetBuilder_custom():\n    def __init__(self, f, c, is_multi, is_reg, ps=None, xtra_fc=None, xtra_cut=0, \n                 custom_head=None, pretrained=True):\n        self.f,self.c,self.is_multi,self.is_reg,self.xtra_cut = f,c,is_multi,is_reg,xtra_cut\n        if xtra_fc is None: xtra_fc = [512]\n        if ps is None: ps = [0.25]*len(xtra_fc) + [0.5]\n        self.ps,self.xtra_fc = ps,xtra_fc\n\n        if f in model_meta: cut,self.lr_cut = model_meta[f]\n        else: cut,self.lr_cut = 0,0\n        cut-=xtra_cut\n        layers = cut_model(f(pretrained), cut)\n        \n        #replace first convolutional layer by 4->64 while keeping corresponding weights\n        #and initializing new weights with zeros\n        w = layers[0].weight\n        layers[0] = nn.Conv2d(4,64,kernel_size=(7,7),stride=(2,2),padding=(3, 3), bias=False)\n        layers[0].weight = torch.nn.Parameter(torch.cat((w,torch.zeros(64,1,7,7)),dim=1))\n        \n        self.nf = model_features[f] if f in model_features else (num_features(layers)*2)\n        if not custom_head: layers += [AdaptiveConcatPool2d(), Flatten()]\n        self.top_model = nn.Sequential(*layers)\n\n        n_fc = len(self.xtra_fc)+1\n        if not isinstance(self.ps, list): self.ps = [self.ps]*n_fc\n\n        if custom_head: fc_layers = [custom_head]\n        else: fc_layers = self.get_fc_layers()\n        self.n_fc = len(fc_layers)\n        self.fc_model = to_gpu(nn.Sequential(*fc_layers))\n        if not custom_head: apply_init(self.fc_model, kaiming_normal)\n        self.model = to_gpu(nn.Sequential(*(layers+fc_layers)))\n\n    @property\n    def name(self): return f'{self.f.__name__}_{self.xtra_cut}'\n\n    def create_fc_layer(self, ni, nf, p, actn=None):\n        res=[nn.BatchNorm1d(num_features=ni)]\n        if p: res.append(nn.Dropout(p=p))\n        res.append(nn.Linear(in_features=ni, out_features=nf))\n        if actn: res.append(actn)\n        return res\n\n    def get_fc_layers(self):\n        res=[]\n        ni=self.nf\n        for i,nf in enumerate(self.xtra_fc):\n            res += self.create_fc_layer(ni, nf, p=self.ps[i], actn=nn.ReLU())\n            ni=nf\n        final_actn = nn.Sigmoid() if self.is_multi else nn.LogSoftmax()\n        if self.is_reg: final_actn = None\n        res += self.create_fc_layer(ni, self.c, p=self.ps[-1], actn=final_actn)\n        return res\n\n    def get_layer_groups(self, do_fc=False):\n        if do_fc:\n            return [self.fc_model]\n        idxs = [self.lr_cut]\n        c = children(self.top_model)\n        if len(c)==3: c = children(c[0])+c[1:]\n        lgs = list(split_by_idxs(c,idxs))\n        return lgs+[self.fc_model]\n    \nclass ConvLearner(Learner):\n    def __init__(self, data, models, precompute=False, **kwargs):\n        self.precompute = False\n        super().__init__(data, models, **kwargs)\n        if hasattr(data, 'is_multi') and not data.is_reg and self.metrics is None:\n            self.metrics = [accuracy_thresh(0.5)] if self.data.is_multi else [accuracy]\n        if precompute: self.save_fc1()\n        self.freeze()\n        self.precompute = precompute\n\n    def _get_crit(self, data):\n        if not hasattr(data, 'is_multi'): return super()._get_crit(data)\n\n        return F.l1_loss if data.is_reg else F.binary_cross_entropy if data.is_multi else F.nll_loss\n\n    @classmethod\n    def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n                   pretrained=True, **kwargs):\n        models = ConvnetBuilder_custom(f, data.c, data.is_multi, data.is_reg,\n            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=pretrained)\n        return cls(data, models, precompute, **kwargs)\n\n    @classmethod\n    def lsuv_learner(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n                  needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=False, **kwargs):\n        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,\n            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=False)\n        convlearn=cls(data, models, precompute, **kwargs)\n        convlearn.lsuv_init()\n        return convlearn\n    \n    @property\n    def model(self): return self.models.fc_model if self.precompute else self.models.model\n    \n    def half(self):\n        if self.fp16: return\n        self.fp16 = True\n        if type(self.model) != FP16: self.models.model = FP16(self.model)\n        if not isinstance(self.models.fc_model, FP16): self.models.fc_model = FP16(self.models.fc_model)\n    def float(self):\n        if not self.fp16: return\n        self.fp16 = False\n        if type(self.models.model) == FP16: self.models.model = self.model.module.float()\n        if type(self.models.fc_model) == FP16: self.models.fc_model = self.models.fc_model.module.float()\n\n    @property\n    def data(self): return self.fc_data if self.precompute else self.data_\n\n    def create_empty_bcolz(self, n, name):\n        return bcolz.carray(np.zeros((0,n), np.float32), chunklen=1, mode='w', rootdir=name)\n\n    def set_data(self, data, precompute=False):\n        super().set_data(data)\n        if precompute:\n            self.unfreeze()\n            self.save_fc1()\n            self.freeze()\n            self.precompute = True\n        else:\n            self.freeze()\n\n    def get_layer_groups(self):\n        return self.models.get_layer_groups(self.precompute)\n\n    def summary(self):\n        precompute = self.precompute\n        self.precompute = False\n        res = super().summary()\n        self.precompute = precompute\n        return res\n\n    def get_activations(self, force=False):\n        tmpl = f'_{self.models.name}_{self.data.sz}.bc'\n        # TODO: Somehow check that directory names haven't changed (e.g. added test set)\n        names = [os.path.join(self.tmp_path, p+tmpl) for p in ('x_act', 'x_act_val', 'x_act_test')]\n        if os.path.exists(names[0]) and not force:\n            self.activations = [bcolz.open(p) for p in names]\n        else:\n            self.activations = [self.create_empty_bcolz(self.models.nf,n) for n in names]\n\n    def save_fc1(self):\n        self.get_activations()\n        act, val_act, test_act = self.activations\n        m=self.models.top_model\n        if len(self.activations[0])!=len(self.data.trn_ds):\n            predict_to_bcolz(m, self.data.fix_dl, act)\n        if len(self.activations[1])!=len(self.data.val_ds):\n            predict_to_bcolz(m, self.data.val_dl, val_act)\n        if self.data.test_dl and (len(self.activations[2])!=len(self.data.test_ds)):\n            if self.data.test_dl: predict_to_bcolz(m, self.data.test_dl, test_act)\n\n        self.fc_data = ImageClassifierData.from_arrays(self.data.path,\n                (act, self.data.trn_y), (val_act, self.data.val_y), self.data.bs, classes=self.data.classes,\n                test = test_act if self.data.test_dl else None, num_workers=8)\n\n    def freeze(self):\n        self.freeze_to(-1)\n\n    def unfreeze(self):\n        self.freeze_to(0)\n        self.precompute = False\n\n    def predict_array(self, arr):\n        precompute = self.precompute\n        self.precompute = False\n        pred = super().predict_array(arr)\n        self.precompute = precompute\n        return pred",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dc68c10a03b6760f34715dc5e77be6dab437ff1b"
      },
      "cell_type": "code",
      "source": "sz = 256 #image size\nbs = 64  #batch size\n\nmd = get_data(sz,bs)\nlearner = ConvLearner.pretrained(arch, md, ps=0.5) #dropout 50%\nlearner.opt_fn = optim.Adam\nlearner.clip = 1.0 #gradient clipping\nlearner.crit = FocalLoss()\nlearner.metrics = [acc]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "79d8846c43cf979eeb9be0bf6e415fe5b30de960"
      },
      "cell_type": "code",
      "source": "learner.lr_find()\nlearner.sched.plot()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bddead11398618e72ad652c55660c31ab9431065"
      },
      "cell_type": "code",
      "source": "lr = 2e-2\nlearner.fit(lr,1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c101ee0a062e02e5369693b38ee0dfbcea0e72f8"
      },
      "cell_type": "code",
      "source": "learner.fit(lrs/4,2,cycle_len=4,use_clr=(10,20))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b7d1f3cdcbc717fbd0c4540e0f1c64b26420e7a6"
      },
      "cell_type": "code",
      "source": "learner.fit(lrs/16,1,cycle_len=8,use_clr=(5,20))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "02289ae783df4cd1ffc6644a19e31e3877becf9c"
      },
      "cell_type": "markdown",
      "source": "Save the model for further use or training on higher resolution images."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c6b600729811362b68a4ba4b6043342c55260499"
      },
      "cell_type": "code",
      "source": "learner.save('ResNet34_256_1')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "02d7926b837fec4088a726a4dc8dca682bbcefbb"
      },
      "cell_type": "markdown",
      "source": "Evaluate the score using Test Time Augmentation (TTA). To evaluate the model, we run inference on all test images. As we have test time augmentation, our results will probably improve if we do predictions multiple times per image and average out the results. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bb2f670782e280fc02225fe2ca2848ca0e973f53"
      },
      "cell_type": "code",
      "source": "def sigmoid_np(x):\n    return 1.0/(1.0 + np.exp(-x))\n\npreds,y = learner.TTA(n_aug=16)\npreds = np.stack(preds, axis=-1)\npreds = sigmoid_np(preds)\npred = preds.max(axis=-1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "56ed27ea44bf67baa702934d1ab5527f74b9318e"
      },
      "cell_type": "markdown",
      "source": "Instead of 0.5, one can adjust the values of the threshold for each class individually to boost the score. The code below does it automatically."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0067372be121cd6bab18215aa916f80ba18220f3"
      },
      "cell_type": "code",
      "source": "def F1_soft(preds,targs,th=0.5,d=50.0):\n    preds = sigmoid_np(d*(preds - th))\n    targs = targs.astype(np.float)\n    score = 2.0*(preds*targs).sum(axis=0)/((preds+targs).sum(axis=0) + 1e-6)\n    return score\n\ndef fit_val(x,y):\n    params = 0.5*np.ones(len(name_label_dict))\n    wd = 1e-5\n    error = lambda p: np.concatenate((F1_soft(x,y,p) - 1.0,\n                                      wd*(p - 0.5)), axis=None)\n    p, success = opt.leastsq(error, params)\n    return p",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "566c454d1a1abce734f458c44ab66f95b60553c2"
      },
      "cell_type": "code",
      "source": "th = fit_val(pred,y)\nth[th<0.1] = 0.1\nprint('Thresholds: ',th)\nprint('F1 macro: ',f1_score(y, pred>th, average='macro'))\nprint('F1 macro (th = 0.5): ',f1_score(y, pred>0.5, average='macro'))\nprint('F1 micro: ',f1_score(y, pred>th, average='micro'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7632a191a74926be3526560f133728f0e33c630c"
      },
      "cell_type": "code",
      "source": "print('Fractions: ',(pred > th).mean(axis=0))\nprint('Fractions (true): ',(y > th).mean(axis=0))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f5f872637f6da43686e7e36e771831565d1416a5"
      },
      "cell_type": "markdown",
      "source": "----------------\n\n# Submit predictions\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c67c22c02a2e9de65b343373546ad6af9c99613e"
      },
      "cell_type": "code",
      "source": "preds_t,y_t = learner.TTA(n_aug=16,is_test=True)\npreds_t = np.stack(preds_t, axis=-1)\npreds_t = sigmoid_np(preds_t)\npred_t = preds_t.max(axis=-1) #max works better for F1 macro score",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f284c01740038056b7dcbe586d80b2048e4c031d"
      },
      "cell_type": "markdown",
      "source": "### Submit the model for evaluation"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "01bf734c6848b13ed9d9597afc697cab47a974e9"
      },
      "cell_type": "code",
      "source": "SAMPLE_SUB = '/kaggle/input/sample_submission.csv'\nsample_df = pd.read_csv(SAMPLE_SUB)\nsample_list = list(sample_df.id)\npred_list = [p for p in preds_t]\npred_dic = dict((key, value) for (key, value) in zip(learn.data.test_ds.fnames,pred_list))\npred_list_cor = [pred_dic[id] for id in sample_list]\ndf = pd.DataFrame({'id':sample_list,'label':pred_list_cor})\ndf.to_csv('{0}_submission.csv'.format(MODEL_PATH), header=True, index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b3933eda99c4a8470e02a6d098103a10dabb3272"
      },
      "cell_type": "markdown",
      "source": "**It is very important to keep the same order of ids as in the sample submission** https://www.kaggle.com/c/human-protein-atlas-image-classification/discussion/69366#409041 since the competition metric relies only on the order of recods ignoring IDs."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8f146ce4551f6eedec22ba5b53582088e6de12a2"
      },
      "cell_type": "code",
      "source": "def save_pred(pred, th=0.5, fname='protein_classification.csv'):\n    pred_list = []\n    for line in pred:\n        s = ' '.join(list([str(i) for i in np.nonzero(line>th)[0]]))\n        pred_list.append(s)\n        \n    sample_df = pd.read_csv(SAMPLE)\n    sample_list = list(sample_df.Id)\n    pred_dic = dict((key, value) for (key, value) \n                in zip(learner.data.test_ds.fnames,pred_list))\n    pred_list_cor = [pred_dic[id] for id in sample_list]\n    df = pd.DataFrame({'Id':sample_list,'Predicted':pred_list_cor})\n    df.to_csv(fname, header=True, index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "af6a7684c511e4617edf4625b0ae9340ce0e25a8"
      },
      "cell_type": "markdown",
      "source": "Similar to validation, additional adjustment may be done based on the public LB probing results (https://www.kaggle.com/c/human-protein-atlas-image-classification/discussion/68678) to predict approximately the same fraction of images of a particular class as expected from the public LB."
    },
    {
      "metadata": {
        "_uuid": "84fb5c492f86bd1947c2936b1cbec023e23c413f"
      },
      "cell_type": "markdown",
      "source": "Somehow the thresholds that I found manually for one of the models are working the best."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bddc0d9dfd4c1c1026a4cf9b25d7f3691b3c5fd5"
      },
      "cell_type": "code",
      "source": "th_t = np.array([0.565,0.39,0.55,0.345,0.33,0.39,0.33,0.45,0.38,0.39,\n               0.34,0.42,0.31,0.38,0.49,0.50,0.38,0.43,0.46,0.40,\n               0.39,0.505,0.37,0.47,0.41,0.545,0.32,0.1])\nprint('Fractions: ',(pred_t > th_t).mean(axis=0))\nsave_pred(pred_t,th_t)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2b2a896031ef4cfe7a95f22dfb2657574d72bb35"
      },
      "cell_type": "markdown",
      "source": "Automatic fitting the thresholds based on the public LB statistics."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3ee9480502118793a0c5b3109d427c9328826815"
      },
      "cell_type": "code",
      "source": "lb_prob = [\n 0.362397820,0.043841336,0.075268817,0.059322034,0.075268817,\n 0.075268817,0.043841336,0.075268817,0.010000000,0.010000000,\n 0.010000000,0.043841336,0.043841336,0.014198783,0.043841336,\n 0.010000000,0.028806584,0.014198783,0.028806584,0.059322034,\n 0.010000000,0.126126126,0.028806584,0.075268817,0.010000000,\n 0.222493880,0.028806584,0.010000000]\n# I replaced 0 by 0.01 since there may be a rounding error leading to 0",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7d3c012cf8946e63cec1ccb827396794ac0901f3"
      },
      "cell_type": "code",
      "source": "def Count_soft(preds,th=0.5,d=50.0):\n    preds = sigmoid_np(d*(preds - th))\n    return preds.mean(axis=0)\n\ndef fit_test(x,y):\n    params = 0.5*np.ones(len(name_label_dict))\n    wd = 1e-5\n    error = lambda p: np.concatenate((Count_soft(x,p) - y,\n                                      wd*(p - 0.5)), axis=None)\n    p, success = opt.leastsq(error, params)\n    return p",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7918e4a836dbbe642f042d9501894862859241a0"
      },
      "cell_type": "code",
      "source": "th_t = fit_test(pred_t,lb_prob)\nth_t[th_t<0.1] = 0.1\nprint('Thresholds: ',th_t)\nprint('Fractions: ',(pred_t > th_t).mean(axis=0))\nprint('Fractions (th = 0.5): ',(pred_t > 0.5).mean(axis=0))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98d3d988dafa17ce30db2e184b21c33f35bed14c"
      },
      "cell_type": "code",
      "source": "save_pred(pred_t,th_t,'protein_classification_f.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "11b6f14336478d1d69e0ed000d1101f80944f0eb"
      },
      "cell_type": "markdown",
      "source": "Save also predictions for a threshold calculated based on the validation set and constant value 0.5:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "555d2bb8b77a77ec3c5a57423fabc190d2eb7b9b"
      },
      "cell_type": "code",
      "source": "save_pred(pred_t,th,'protein_classification_v.csv')\nsave_pred(pred_t,0.5,'protein_classification_05.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f78d99b5f65e592f9ed6e76cd1629adf5163cb38"
      },
      "cell_type": "markdown",
      "source": "Try using the threshold from validation set for classes not present in the public LB:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a78dbd9b29a99cd94c64e54a01c077e49b00a433"
      },
      "cell_type": "code",
      "source": "class_list = [8,9,10,15,20,24,27]\nfor i in class_list:\n    th_t[i] = th[i]\nsave_pred(pred_t,th_t,'protein_classification_c.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fc2dadec42b378b1d6ca1c2f059d061d18599738"
      },
      "cell_type": "markdown",
      "source": "Try fitting thresholds based on the frequency of classes in the train dataset:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f63836c180e728e906d1445fc63f42e9ed49860"
      },
      "cell_type": "code",
      "source": "labels = pd.read_csv(LABELS).set_index('Id')\nlabel_count = np.zeros(len(name_label_dict))\nfor label in labels['Target']:\n    l = [int(i) for i in label.split()]\n    label_count += np.eye(len(name_label_dict))[l].sum(axis=0)\nlabel_fraction = label_count.astype(np.float)/len(labels)\nlabel_count, label_fraction",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2e76703941f9c19edfe0d8bf259edefe969dde7a"
      },
      "cell_type": "code",
      "source": "th_t = fit_test(pred_t,label_fraction)\nth_t[th_t<0.05] = 0.05\nprint('Thresholds: ',th_t)\nprint('Fractions: ',(pred_t > th_t).mean(axis=0))\nsave_pred(pred_t,th_t,'protein_classification_t.csv')",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}