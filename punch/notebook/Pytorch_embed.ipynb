{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#misc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "# pytorch\n",
    "from torch.utils.data import DataLoader as torch_dl\n",
    "from torch.utils.data import Dataset\n",
    "from torch import  nn\n",
    "from torch import optim\n",
    "from torch.nn.init import *\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "DIR = \"../input\"\n",
    "\n",
    "colnames = ['Time', 'Duration', 'SrcDevice', 'DstDevice', 'Protocol', 'SrcPort', 'DstPort', 'SrcPackets', \n",
    "       'DstPackets', 'SrcBytes', 'DstBytes']\n",
    "cat_vars = ['SrcDevice', 'DstDevice','Protocol','SrcPort', 'DstPort']\n",
    "cont_vars = ['Time', 'Duration', 'SrcPackets', 'DstPackets', 'SrcBytes', 'DstBytes']\n",
    "train_df = pd.read_csv(os.path.join(DIR, 'netflow_day-03.csv'),names = colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['SrcDevice'] = train_df['SrcDevice'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4420\n",
       "1    10428\n",
       "2     8268\n",
       "3     6348\n",
       "4     6348\n",
       "Name: SrcDevice, dtype: int16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.SrcDevice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "# FUNCTIONS\n",
    "#########################################################################################################\n",
    "\n",
    "def preprocess(data, cat_vars):\n",
    "    for i in cat_vars:\n",
    "        data[f'{i}'] = data[f'{i}'].astype('category').cat.codes\n",
    "    return data\n",
    "    \n",
    "\n",
    "def EmbeddingDataPreprocess(data, cats, inplace =True):\n",
    "    ### Each categorical column should have indices as values \n",
    "    ### Which will be looked up at embedding matrix and used in modeling\n",
    "    ### Make changes inplace\n",
    "    if inplace:\n",
    "        for c in cats:\n",
    "            data[c].replace({val:i  for i, val in enumerate(data[c].unique())}, inplace=True)\n",
    "        return data\n",
    "    else:\n",
    "        data_copy = data.copy()\n",
    "        for c in cats:\n",
    "            data_copy[c].replace({val:i  for i, val in enumerate(data_copy[c].unique())}, inplace=True)\n",
    "        return data_copy\n",
    "        \n",
    "def get_embs_dims(data, cats):\n",
    "    cat_sz = [len(data[c].unique()) for c in cats]\n",
    "    return [(c, min(50, (c+1)//2)) for c in cat_sz]\n",
    "    \n",
    "    \n",
    "def emb_init(x):\n",
    "    x = x.weight.data\n",
    "    sc = 2/(x.size(1)+1)\n",
    "    x.uniform_(-sc,sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "# CLASSES\n",
    "#########################################################################################################\n",
    "\n",
    "class EmbeddingDataset(Dataset):\n",
    "    ### This dataset will prepare inputs cats, conts and output y \n",
    "    ### To be feed into our mixed input embedding fully connected NN model \n",
    "    ### Stacks numpy arrays to create nxm matrices where n = rows, m = columns\n",
    "    ### Gives y 0 if not specified\n",
    "    def __init__(self, cats, conts, y):\n",
    "        n = len(cats[0]) if cats else len(conts[0])\n",
    "        self.cats = np.stack(cats, 1).astype(np.int64) if cats else np.zeros((n,1))\n",
    "        self.conts = np.stack(conts, 1).astype(np.float32) if conts else np.zeros((n,1))\n",
    "        self.y = np.zeros((n,1)) if y is None else y[:,None].astype(np.float32)\n",
    "        \n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.cats[idx], self.conts[idx], self.y[idx]]\n",
    "    \n",
    "    @classmethod\n",
    "    def from_data_frames(cls, df_cat, df_cont, y=None):\n",
    "        cat_cols = [c.values for n,c in df_cat.items()]\n",
    "        cont_cols = [c.values for n,c in df_cont.items()]\n",
    "        return cls(cat_cols, cont_cols, y)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frame(cls, df, cat_flds, y=None):\n",
    "        return cls.from_data_frames(df[cat_flds], df.drop(cat_flds, axis=1), y)        \n",
    "        \n",
    "        \n",
    "        \n",
    "### We will keep this for fastai compatibility\n",
    "class ModelData():\n",
    "    def __init__(self, path, trn_dl, val_dl, test_dl=None):\n",
    "        self.path,self.trn_dl,self.val_dl,self.test_dl = path,trn_dl,val_dl,test_dl\n",
    "        \n",
    "    \n",
    "class EmbeddingModelData(ModelData):\n",
    "    ### This class provides training and validation dataloaders\n",
    "    ### Which we will use in our model\n",
    "    \n",
    "    def __init__(self, path, trn_ds, val_ds, bs, test_ds=None):\n",
    "        test_dl = DataLoader(test_ds, bs, shuffle=False, num_workers=1) if test_ds is not None else None\n",
    "        super().__init__(path, torch_dl(trn_ds, batch_size=bs, shuffle=True, num_workers=1)\n",
    "                         ,torch_dl(val_ds, batch_size=bs, shuffle=True, num_workers=1), test_ds)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_data_frames(cls, path, trn_df, val_df, trn_y, val_y, cat_flds, bs, test_df=None):\n",
    "        test_ds = EmbeddingDataset.from_data_frame(test_df, cat_flds) if test_df is not None else None\n",
    "        return cls(path, EmbeddingDataset.from_data_frame(trn_df, cat_flds, trn_y),\n",
    "                    EmbeddingDataset.from_data_frame(val_df, cat_flds,val_y), bs, test_ds=test_ds)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frame(cls, path, val_idxs, trn_idxs, df, y, cat_flds, bs, test_df=None):\n",
    "        val_df, val_y = df.iloc[val_idxs], y[val_idxs]\n",
    "        trn_df, trn_y = df.iloc[trn_idxs], y[trn_idxs]\n",
    "        return cls.from_data_frames(path, trn_df, val_df, trn_y, val_y, cat_flds, bs, test_df)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops, y_range=None, use_bn=False, classify=None):\n",
    "        super().__init__() ## inherit from nn.Module parent class\n",
    "        self.embs = nn.ModuleList([nn.Embedding(m, d) for m, d in emb_szs]) ## construct embeddings\n",
    "        for emb in self.embs: emb_init(emb)                                 ## initialize embedding weights\n",
    "        n_emb = sum(e.embedding_dim for e in self.embs)                     ## get embedding dimension needed for 1st layer\n",
    "        szs = [n_emb+n_cont] + szs                                          ## add input layer to szs\n",
    "        self.lins = nn.ModuleList([\n",
    "            nn.Linear(szs[i], szs[i+1]) for i in range(len(szs)-1)])        ## create linear layers input, l1 -> l1, l2 ...\n",
    "        self.bns = nn.ModuleList([\n",
    "            nn.BatchNorm1d(sz) for sz in szs[1:]])                          ## batch normalization for hidden layers activations\n",
    "        for o in self.lins: kaiming_normal(o.weight.data)                   ## init weights with kaiming normalization\n",
    "        self.outp = nn.Linear(szs[-1], out_sz)                              ## create linear from last hidden layer to output\n",
    "        kaiming_normal(self.outp.weight.data)                               ## do kaiming initialization\n",
    "        \n",
    "        self.emb_drop = nn.Dropout(emb_drop)                                ## embedding dropout, will zero out weights of embeddings\n",
    "        self.drops = nn.ModuleList([nn.Dropout(drop) for drop in drops])    ## fc layer dropout\n",
    "        self.bn = nn.BatchNorm1d(n_cont)                                    ## bacthnorm for continous data\n",
    "        self.use_bn,self.y_range = use_bn,y_range \n",
    "        self.classify = classify\n",
    "        \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x = [emb(x_cat[:, i]) for i, emb in enumerate(self.embs)] ## takes necessary emb vectors \n",
    "        x = torch.cat(x, 1) ## concatenate along axis = 1 (columns - side by side) # this is our input from cats\n",
    "        x = self.emb_drop(x) ## apply dropout to elements of embedding tensor\n",
    "        x2 = self.bn(x_cont) ## apply batchnorm to continous variables\n",
    "        x = torch.cat([x, x2], 1) ## concatenate cats and conts for final input\n",
    "        for l, d, b in zip(self.lins, self.drops, self.bns):\n",
    "            x = F.relu(l(x)) ## dotprod + non-linearity\n",
    "            if self.use_bn: x = b(x) ## apply batchnorm activations\n",
    "            x = d(x) ## apply dropout to activations\n",
    "        x = self.outp(x) # we defined this externally just not to apply dropout to output\n",
    "        if self.classify:\n",
    "            x = F.sigmoid(x) # for classification\n",
    "        elif y_range:\n",
    "            x = F.sigmoid(x) ## scales the output between 0,1\n",
    "            x = x*(self.y_range[1] - self.y_range[0]) ## scale output\n",
    "            x = x + self.y_range[0] ## shift output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "# RUN MODEL\n",
    "#########################################################################################################\n",
    "\n",
    "        \n",
    "    \n",
    "train.columns = ['id', 'name', 'item_condition_id', 'category_name', 'brand_name',\n",
    "       'price', 'shipping', 'item_description']\n",
    "\n",
    "test['price'] = 0\n",
    "test.columns = ['id', 'name', 'item_condition_id', 'category_name', 'brand_name',\n",
    "       'shipping', 'item_description', 'price']\n",
    "        \n",
    "        \n",
    "        \n",
    "train_test = pd.concat([train, test],0)    \n",
    "train_test.drop(['id', 'name', 'item_description'], axis=1, inplace=True)    \n",
    "train_test = preprocess(train_test)\n",
    "train_test = train_test.reset_index(drop=True)\n",
    "cats = ['item_condition_id', 'category_name', 'brand_name']\n",
    "train_test = EmbeddingDataPreprocess(train_test, cats, inplace=True)\n",
    "train_df = train_test.iloc[range(len(train))]\n",
    "test_df = train_test.iloc[range(len(train),len(train_test))]\n",
    "        \n",
    "\n",
    "del train\n",
    "test_id = test['id']\n",
    "del test\n",
    "gc.collect()\n",
    "        \n",
    "        \n",
    "train_input, train_y = train_df.drop('price', 1), np.log(train_df.price + 1)\n",
    "test_input, test_y = test_df.drop('price', 1), np.log(test_df.price + 1)\n",
    "y_range = (train_y.min(), train_y.max())\n",
    "emb_szs = get_embs_dims(train_test, cats)\n",
    "       \n",
    "model_data = EmbeddingModelData.from_data_frames('./tmp', train_input, test_input, train_y, test_y, cats, bs=32) \n",
    "emb_model = EmbeddingModel(emb_szs, 1, 0.04, 1, [1000, 500], [0.001, 0.01], y_range = y_range, classify=None)\n",
    "        \n",
    "        \n",
    "def embedding_train(model, model_data, optimizer, criterion, epochs):    \n",
    "    for epoch in range(epochs):\n",
    "        for data in iter(model_data.trn_dl):\n",
    "            \n",
    "            # get inputs\n",
    "            x_cats, x_conts, y = data\n",
    "\n",
    "            # wrap with variable\n",
    "            x_cats, x_conts, y = Variable(x_cats), Variable(x_conts), Variable(y)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(x_cats, x_conts)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        \n",
    "# First training\n",
    "opt = optim.SGD(emb_model.parameters(), lr = 1e-4, weight_decay=1e-4)\n",
    "crit = F.mse_loss\n",
    "epochs = 1\n",
    "embedding_train(emb_model, model_data, opt, crit, 1)\n",
    "\n",
    "# Second training\n",
    "opt = optim.SGD(emb_model.parameters(), lr = 5e-4, weight_decay=1e-4)\n",
    "crit = F.mse_loss\n",
    "epochs = 1\n",
    "embedding_train(emb_model, model_data, opt, crit, 1)\n",
    "\n",
    "\n",
    "# Make predictions \n",
    "preds = emb_model(Variable(LongTensor(model_data.val_dl.dataset.cats)),\n",
    "                   Variable(FloatTensor(model_data.val_dl.dataset.conts)))\n",
    "\n",
    "\n",
    "pd.DataFrame({'test_id':test_id, 'price':(np.exp(preds.flatten()) - 1)}).to_csv('predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
